<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="description" content="Bayesian linear regression (BLR) models:
- unified mapping of genetic variants, estimation of genetic parameters 
(e.g. heritability) and prediction of disease risk)
- handles different genetic architectures (few large, many small effects)
- scale to large data (e.g. sparse LD)

In the Bayesian multiple regression model the posterior density of the 
model parameters depend on the likelihood of the data given 
the parameters and a prior probability for the model parameters
The prior density of marker effects defines whether the model will 
induce variable selection and shrinkage or shrinkage only. 
Also, the choice of prior will define the extent and type of shrinkage induced.
Ideally the choice of prior for the marker effect should reflect the genetic 
architecture of the trait, and will vary (perhaps a lot) across traits.

The following prior distributions are provided:
Bayes N: Assigning a Gaussian prior to marker effects implies that the posterior means are the 
BLUP estimates (same as Ridge Regression).
Bayes L: Assigning a double-exponential or Laplace prior is the density used in 
the Bayesian LASSO
Bayes A: similar to ridge regression but t-distribution prior (rather than Gaussian) 
for the marker effects ; variance comes from an inverse-chi-square distribution instead of being fixed. Estimation 
via Gibbs sampling.
Bayes C: uses a “rounded spike” (low-variance Gaussian) at origin many small 
effects can contribute to polygenic component, reduces the dimensionality of 
the model (makes Gibbs sampling feasible).
Bayes R: Hierarchical Bayesian mixture model with 4 Gaussian components, with 
variances scaled by 0, 0.0001 , 0.001 , and 0.01 ."><title>Bayesian linear regression models — gbayes • qgg</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Bayesian linear regression models — gbayes"><meta property="og:description" content="Bayesian linear regression (BLR) models:
- unified mapping of genetic variants, estimation of genetic parameters 
(e.g. heritability) and prediction of disease risk)
- handles different genetic architectures (few large, many small effects)
- scale to large data (e.g. sparse LD)

In the Bayesian multiple regression model the posterior density of the 
model parameters depend on the likelihood of the data given 
the parameters and a prior probability for the model parameters
The prior density of marker effects defines whether the model will 
induce variable selection and shrinkage or shrinkage only. 
Also, the choice of prior will define the extent and type of shrinkage induced.
Ideally the choice of prior for the marker effect should reflect the genetic 
architecture of the trait, and will vary (perhaps a lot) across traits.

The following prior distributions are provided:
Bayes N: Assigning a Gaussian prior to marker effects implies that the posterior means are the 
BLUP estimates (same as Ridge Regression).
Bayes L: Assigning a double-exponential or Laplace prior is the density used in 
the Bayesian LASSO
Bayes A: similar to ridge regression but t-distribution prior (rather than Gaussian) 
for the marker effects ; variance comes from an inverse-chi-square distribution instead of being fixed. Estimation 
via Gibbs sampling.
Bayes C: uses a “rounded spike” (low-variance Gaussian) at origin many small 
effects can contribute to polygenic component, reduces the dimensionality of 
the model (makes Gibbs sampling feasible).
Bayes R: Hierarchical Bayesian mixture model with 4 Gaussian components, with 
variances scaled by 0, 0.0001 , 0.001 , and 0.01 ."><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">qgg</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.1.2</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul><form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off"></form>

      <ul class="navbar-nav"><li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/psoerensen/qgg/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div>

    
  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Bayesian linear regression models</h1>
      <small class="dont-index">Source: <a href="https://github.com/psoerensen/qgg/blob/HEAD/R/genomic_bayes.R" class="external-link"><code>R/genomic_bayes.R</code></a></small>
      <div class="d-none name"><code>gbayes.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Bayesian linear regression (BLR) models:</p>
<p>- unified mapping of genetic variants, estimation of genetic parameters 
(e.g. heritability) and prediction of disease risk)</p>
<p>- handles different genetic architectures (few large, many small effects)</p>
<p>- scale to large data (e.g. sparse LD)</p>

<p>In the Bayesian multiple regression model the posterior density of the 
model parameters depend on the likelihood of the data given 
the parameters and a prior probability for the model parameters</p>
<p>The prior density of marker effects defines whether the model will 
induce variable selection and shrinkage or shrinkage only. 
Also, the choice of prior will define the extent and type of shrinkage induced.
Ideally the choice of prior for the marker effect should reflect the genetic 
architecture of the trait, and will vary (perhaps a lot) across traits.</p>

<p>The following prior distributions are provided:</p>
<p>Bayes N: Assigning a Gaussian prior to marker effects implies that the posterior means are the 
BLUP estimates (same as Ridge Regression).</p>
<p>Bayes L: Assigning a double-exponential or Laplace prior is the density used in 
the Bayesian LASSO</p>
<p>Bayes A: similar to ridge regression but t-distribution prior (rather than Gaussian) 
for the marker effects ; variance comes from an inverse-chi-square distribution instead of being fixed. Estimation 
via Gibbs sampling.</p>
<p>Bayes C: uses a “rounded spike” (low-variance Gaussian) at origin many small 
effects can contribute to polygenic component, reduces the dimensionality of 
the model (makes Gibbs sampling feasible).</p>
<p>Bayes R: Hierarchical Bayesian mixture model with 4 Gaussian components, with 
variances scaled by 0, 0.0001 , 0.001 , and 0.01 .</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">gbayes</span><span class="op">(</span></span>
<span>  y <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  X <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  W <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  stat <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  covs <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  trait <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  fit <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  Glist <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  chr <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  rsids <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  b <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  bm <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  seb <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  LD <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  n <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  formatLD <span class="op">=</span> <span class="st">"dense"</span>,</span>
<span>  vg <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  vb <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  ve <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  ssg_prior <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  ssb_prior <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  sse_prior <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  lambda <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  scaleY <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  h2 <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  pi <span class="op">=</span> <span class="fl">0.001</span>,</span>
<span>  updateB <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  updateG <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  updateE <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  updatePi <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  adjustE <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  models <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  nug <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  nub <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  nue <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  msize <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  mask <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  GRMlist <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  ve_prior <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  vg_prior <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  tol <span class="op">=</span> <span class="fl">0.001</span>,</span>
<span>  nit <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  nburn <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  nit_local <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  nit_global <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  method <span class="op">=</span> <span class="st">"mixed"</span>,</span>
<span>  algorithm <span class="op">=</span> <span class="st">"mcmc"</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>
    <dl><dt>y</dt>
<dd><p>is a vector or matrix of phenotypes</p></dd>


<dt>X</dt>
<dd><p>is a matrix of covariates</p></dd>


<dt>W</dt>
<dd><p>is a matrix of centered and scaled genotypes</p></dd>


<dt>stat</dt>
<dd><p>dataframe with marker summary statistics</p></dd>


<dt>covs</dt>
<dd><p>is a list of summary statistics (output from internal cvs function)</p></dd>


<dt>trait</dt>
<dd><p>is an integer used for selection traits in covs object</p></dd>


<dt>fit</dt>
<dd><p>is a list of results from gbayes</p></dd>


<dt>Glist</dt>
<dd><p>list of information about genotype matrix stored on disk</p></dd>


<dt>chr</dt>
<dd><p>is the chromosome for which to fit BLR models</p></dd>


<dt>rsids</dt>
<dd><p>is a character vector of rsids</p></dd>


<dt>b</dt>
<dd><p>is a vector or matrix of marginal marker effects</p></dd>


<dt>bm</dt>
<dd><p>is a vector or matrix of adjusted marker effects for the BLR model</p></dd>


<dt>seb</dt>
<dd><p>is a vector or matrix of standard error of marginal effects</p></dd>


<dt>LD</dt>
<dd><p>is a list with sparse LD matrices</p></dd>


<dt>n</dt>
<dd><p>is a scalar or vector of number of observations for each trait</p></dd>


<dt>formatLD</dt>
<dd><p>is a character specifying LD format (formatLD="dense" is default)</p></dd>


<dt>vg</dt>
<dd><p>is a scalar or matrix of genetic (co)variances</p></dd>


<dt>vb</dt>
<dd><p>is a scalar or matrix of marker (co)variances</p></dd>


<dt>ve</dt>
<dd><p>is a scalar or matrix of residual (co)variances</p></dd>


<dt>ssg_prior</dt>
<dd><p>is a scalar or matrix of prior genetic (co)variances</p></dd>


<dt>ssb_prior</dt>
<dd><p>is a scalar or matrix of prior marker (co)variances</p></dd>


<dt>sse_prior</dt>
<dd><p>is a scalar or matrix of prior residual (co)variances</p></dd>


<dt>lambda</dt>
<dd><p>is a vector or matrix of lambda values</p></dd>


<dt>scaleY</dt>
<dd><p>is a logical; if TRUE y is centered and scaled</p></dd>


<dt>h2</dt>
<dd><p>is the trait heritability</p></dd>


<dt>pi</dt>
<dd><p>is the proportion of markers in each marker variance class (e.g. pi=c(0.999,0.001),used if method="ssvs")</p></dd>


<dt>updateB</dt>
<dd><p>is a logical for updating marker (co)variances</p></dd>


<dt>updateG</dt>
<dd><p>is a logical for updating genetic (co)variances</p></dd>


<dt>updateE</dt>
<dd><p>is a logical for updating residual (co)variances</p></dd>


<dt>updatePi</dt>
<dd><p>is a logical for updating pi</p></dd>


<dt>adjustE</dt>
<dd><p>is a logical for adjusting residual variance</p></dd>


<dt>models</dt>
<dd><p>is a list structure with models evaluated in bayesC</p></dd>


<dt>nug</dt>
<dd><p>is a scalar or vector of prior degrees of freedom for prior genetic (co)variances</p></dd>


<dt>nub</dt>
<dd><p>is a scalar or vector of prior degrees of freedom for marker (co)variances</p></dd>


<dt>nue</dt>
<dd><p>is a scalar or vector of prior degrees of freedom for prior residual (co)variances</p></dd>


<dt>verbose</dt>
<dd><p>is a logical; if TRUE it prints more details during iteration</p></dd>


<dt>msize</dt>
<dd><p>number of markers used in compuation of sparseld</p></dd>


<dt>mask</dt>
<dd><p>is a vector or matrix of TRUE/FALSE specifying if marker should be ignored</p></dd>


<dt>GRMlist</dt>
<dd><p>is a list providing information about GRM matrix stored in binary files on disk</p></dd>


<dt>ve_prior</dt>
<dd><p>is a scalar or matrix of prior residual (co)variances</p></dd>


<dt>vg_prior</dt>
<dd><p>is a scalar or matrix of prior genetic (co)variances</p></dd>


<dt>tol</dt>
<dd><p>is tolerance, i.e. convergence criteria used in gbayes</p></dd>


<dt>nit</dt>
<dd><p>is the number of iterations</p></dd>


<dt>nburn</dt>
<dd><p>is the number of burnin iterations</p></dd>


<dt>nit_local</dt>
<dd><p>is the number of local iterations</p></dd>


<dt>nit_global</dt>
<dd><p>is the number of global iterations</p></dd>


<dt>method</dt>
<dd><p>specifies the methods used (method="bayesN","bayesA","bayesL","bayesC","bayesR")</p></dd>


<dt>algorithm</dt>
<dd><p>specifies the algorithm</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    

<p>Returns a list structure including</p>
<dl><dt>b</dt>
<dd><p>vector or matrix (mxt) of posterior means for marker effects</p></dd>

<dt>d</dt>
<dd><p>vector or matrix (mxt) of posterior means for marker inclusion probabilities</p></dd>

<dt>vb</dt>
<dd><p>scalar or vector (t) of posterior means for marker variances</p></dd>

<dt>vg</dt>
<dd><p>scalar or vector (t) of posterior means for genomic variances</p></dd>

<dt>ve</dt>
<dd><p>scalar or vector (t) of posterior means for residual variances</p></dd>

<dt>rb</dt>
<dd><p>matrix (txt) of posterior means for marker correlations</p></dd>

<dt>rg</dt>
<dd><p>matrix (txt) of posterior means for genomic correlations</p></dd>

<dt>re</dt>
<dd><p>matrix (txt) of posterior means for residual correlations</p></dd>

<dt>pi</dt>
<dd><p>vector (1xnmodels) of posterior probabilities for models</p></dd>

<dt>h2</dt>
<dd><p>vector (1xt) of posterior means for model probability</p></dd>

<dt>param</dt>
<dd><p>a list current parameters (same information as item listed above) used for restart of the analysis</p></dd>

<dt>stat</dt>
<dd><p>matrix (mxt) of marker information and effects used for genomic risk scoring</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="author">Author<a class="anchor" aria-label="anchor" href="#author"></a></h2>
    <p>Peter Sørensen</p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span></span>
<span></span>
<span><span class="co"># Simulate data and test functions</span></span>
<span></span>
<span><span class="va">W</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">100000</span><span class="op">)</span>,nrow<span class="op">=</span><span class="fl">1000</span><span class="op">)</span></span>
<span><span class="va">set1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">W</span><span class="op">)</span>,<span class="fl">5</span><span class="op">)</span></span>
<span><span class="va">set2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">W</span><span class="op">)</span>,<span class="fl">5</span><span class="op">)</span></span>
<span><span class="va">sets</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">set1</span>,<span class="va">set2</span><span class="op">)</span></span>
<span><span class="va">g</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html" class="external-link">rowSums</a></span><span class="op">(</span><span class="va">W</span><span class="op">[</span>,<span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">set1</span>,<span class="va">set2</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">e</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">W</span><span class="op">)</span>,mean<span class="op">=</span><span class="fl">0</span>,sd<span class="op">=</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">g</span> <span class="op">+</span> <span class="va">e</span></span>
<span></span>
<span></span>
<span><span class="va">fitM</span> <span class="op">&lt;-</span> <span class="fu">gbayes</span><span class="op">(</span>y<span class="op">=</span><span class="va">y</span>, W<span class="op">=</span><span class="va">W</span>, method<span class="op">=</span><span class="st">"bayesN"</span><span class="op">)</span></span>
<span><span class="va">fitA</span> <span class="op">&lt;-</span> <span class="fu">gbayes</span><span class="op">(</span>y<span class="op">=</span><span class="va">y</span>, W<span class="op">=</span><span class="va">W</span>, method<span class="op">=</span><span class="st">"bayesA"</span><span class="op">)</span></span>
<span><span class="va">fitL</span> <span class="op">&lt;-</span> <span class="fu">gbayes</span><span class="op">(</span>y<span class="op">=</span><span class="va">y</span>, W<span class="op">=</span><span class="va">W</span>, method<span class="op">=</span><span class="st">"bayesL"</span><span class="op">)</span></span>
<span><span class="va">fitC</span> <span class="op">&lt;-</span> <span class="fu">gbayes</span><span class="op">(</span>y<span class="op">=</span><span class="va">y</span>, W<span class="op">=</span><span class="va">W</span>, method<span class="op">=</span><span class="st">"bayesC"</span><span class="op">)</span></span>
<span></span>
<span></span></code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p></p><p>Developed by Peter Soerensen, Palle Duun Rohde, Izel Fourie Soerensen.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer></div>

  

  

  </body></html>

